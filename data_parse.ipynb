{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T23:20:27.470193Z",
     "start_time": "2019-09-17T23:20:07.128053Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "from tqdm import tqdm_notebook\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T23:20:27.489319Z",
     "start_time": "2019-09-17T23:20:27.473450Z"
    }
   },
   "outputs": [],
   "source": [
    "retain_fields = ['date', 'case_number', 'employer', 'tot_foreign_positions', 'naic_code', 'job_title', 'job_code',\n",
    "                 'soc_name', 'approval_status', 'annual_wage', 'annual_prevailing_wage', 'city',\n",
    "                 'state', 'county', 'year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fax data 02-06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noted that there's no available fax data in 2007, so we load the fax data between 2002 and 2006:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T23:20:30.909856Z",
     "start_time": "2019-09-17T23:20:27.490334Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a14ade1676ab45cab422def8356eaab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for year in tqdm_notebook(range(2002, 2007)):\n",
    "    year_str = str(year)[-2:]\n",
    "    globals()['fax_'+year_str] = pd.read_csv('dataset/h1b_Fax_FY'+year_str+'.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For fax data, the fields `date`, `tot_foreign_positions`, `naic_code`, `soc_name`, `county` are missing, so we set the values of these fields to be `np.nan`\n",
    "\n",
    "- The fields `case_number`, `employer`, `job_title`, `job_code`, `approval_status`, `city`, `state` can be directly obtained from the raw data, we just need to modify their names\n",
    "\n",
    "- The fields `annual_wage`, `annual_prevailing_wage` need to be calculated using wages and units. So, we need to convert them from string-type to numerical-type using function `str2num` and `rp2num`\n",
    "\n",
    "- We add a column `year` to represent the year of data source\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T23:20:30.961085Z",
     "start_time": "2019-09-17T23:20:30.913554Z"
    }
   },
   "outputs": [],
   "source": [
    "def str2num(x):\n",
    "    '''\n",
    "    change string-type number to float\n",
    "    '''\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        x = x.replace(',', '')\n",
    "        if x[0] == '$':\n",
    "            x = x[1:]\n",
    "        try:\n",
    "            return float(x)\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "\n",
    "def rp2num(x):\n",
    "    '''\n",
    "    change RatePer to frequency number\n",
    "    '''\n",
    "    if x in ['Y', 'y']:\n",
    "        return 1\n",
    "    elif x in ['M', 'm']:\n",
    "        return 12\n",
    "    elif x in ['B', 'b']:\n",
    "        return 26\n",
    "    elif x in ['W', 'w']:\n",
    "        return 52\n",
    "    elif x in ['H', 'h']:\n",
    "        return 2080\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def process_fax_data(data, year):\n",
    "    '''\n",
    "    data parsing function for fax data\n",
    "    '''\n",
    "    data_ = data.rename(columns={'Case Number': 'C_num'})\n",
    "    used_cols = ['C_num', 'EmpName', 'JobTitle', 'JobCode',\n",
    "                 'CertCode', 'WageRateFrom', 'RatePer', 'PrevWage_1',\n",
    "                 'PrevWagePer_1', 'WorkCity_1', 'WorkState_1']\n",
    "    data_ = data_[used_cols]\n",
    "    # add a 'year' col to represent the year\n",
    "    data_['year'] = year\n",
    "    data_['WageRateFrom'] = data_['WageRateFrom'].apply(str2num)\n",
    "    data_['PrevWage_1'] = data_['PrevWage_1'].apply(str2num)\n",
    "    data_['annual_wage'] = data_['WageRateFrom']*data_['RatePer'].apply(rp2num)\n",
    "    data_['annual_prevailing_wage'] = data_[\n",
    "        'PrevWage_1']*data_['PrevWagePer_1'].apply(rp2num)\n",
    "    # change the columns' name as required and retain necessary cols\n",
    "    col_trans_dict = {'C_num': 'case_number', 'EmpName': 'employer', 'JobTitle': 'job_title',\n",
    "                      'JobCode': 'job_code', 'CertCode': 'approval_status',\n",
    "                      'WorkCity_1': 'city', 'WorkState_1': 'state'}\n",
    "    data_ = data_.rename(columns=col_trans_dict)\n",
    "    # fax data don't contain some certain fields, set them to nan\n",
    "    missing_cols = ['date', 'tot_foreign_positions',\n",
    "                    'naic_code', 'soc_name', 'county']\n",
    "    data_ = pd.concat([data_, pd.DataFrame(columns=missing_cols)], axis=1)\n",
    "    return data_[retain_fields]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we apply the function `process_fax_data` to the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T23:20:32.880791Z",
     "start_time": "2019-09-17T23:20:30.961085Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d2d754266b343aabd0cc4c285c398c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for year in tqdm_notebook(range(2002, 2007)):\n",
    "    year_str = str(year)[-2:]\n",
    "    globals()['fax_'+year_str] = process_fax_data(globals()\n",
    "                                                  ['fax_'+year_str], year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efile data 02-07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we load efile data from 2002 to 2007:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T23:20:51.244140Z",
     "start_time": "2019-09-17T23:20:32.880791Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b8916f0efb4fe1a2b649963ac1ecef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (25,29,33,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (28,30,31,32,34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (16,26,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for year in tqdm_notebook(range(2002, 2008)):\n",
    "    year_str = str(year)[-2:]\n",
    "    globals()['efile_'+year_str] = pd.read_csv('dataset/h1b_efile_FY' +\n",
    "                                               year_str+'.txt', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For efile data:\n",
    "\n",
    "- The fields `tot_foreign_positions`, `naic_code`, `soc_name`, `county` are missing, so we set the values of these fields to be `np.nan`\n",
    "\n",
    "- The fields `date`, `case_number`, `employer`, `job_title`, `job_code`, `approval_status`, `city`, `state` can be directly obtained from the raw data, we just need to modify their names\n",
    "\n",
    "- The fields `annual_wage`, `annual_prevailing_wage` need to be calculated using wages and units. So, we need to convert them from string-type to numerical-type using function `str2num` and `rp2num`\n",
    "\n",
    "- We convert the type of `date` from string to datetime\n",
    "\n",
    "- We add a column `year` to represent the year of data source\n",
    "\n",
    "- For year 2007, we need to do some additional work: we extract H1B data by specifying the `Program Designation` to be **R**. Also, we need to drop two columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T23:20:51.297403Z",
     "start_time": "2019-09-17T23:20:51.244140Z"
    }
   },
   "outputs": [],
   "source": [
    "efile_cols = efile_02.columns\n",
    "\n",
    "\n",
    "def str2num(x):\n",
    "    '''\n",
    "    change string-type number to float\n",
    "    '''\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        x = x.replace(',', '')\n",
    "        if x[0] == '$':\n",
    "            x = x[1:]\n",
    "        try:\n",
    "            return float(x)\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "\n",
    "def rp2num(x):\n",
    "    '''\n",
    "    change RatePer to frequency number\n",
    "    '''\n",
    "    trans_dict = {'Year': 1, 'Month': 12,\n",
    "                  '2 weeks': 26, 'Week': 52, 'Hour': 2080}\n",
    "    try:\n",
    "        return trans_dict[x]\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def str2time(x):\n",
    "    '''\n",
    "    change string-type time to datetime\n",
    "    '''\n",
    "    try:\n",
    "        return datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "\n",
    "def process_efile_data(data, year):\n",
    "    '''\n",
    "    data parsing function for efile data\n",
    "    '''\n",
    "    data_ = data.copy()\n",
    "    # extra parsing for 07's data\n",
    "    if year == 2007:\n",
    "        data_ = data_[data['Program Designation'] == 'R']\n",
    "        data_.drop(['Program Designation', 'Withdrawn'], axis=1, inplace=True)\n",
    "        data_.columns = efile_cols\n",
    "    used_cols = ['SUBMITTED_DATE', 'CASE_NO', 'NAME', 'CITY_1', 'STATE_1',\n",
    "                 'JOB_TITLE', 'JOB_CODE', 'APPROVAL_STATUS', 'WAGE_RATE_1',\n",
    "                 'RATE_PER_1', 'PREVAILING_WAGE_1']\n",
    "    data_ = data_[used_cols]\n",
    "    data_['year'] = year\n",
    "    data_['SUBMITTED_DATE'] = data_['SUBMITTED_DATE'].apply(str2time)\n",
    "    data_['WAGE_RATE_1'] = data_['WAGE_RATE_1'].apply(str2num)\n",
    "    data_['PREVAILING_WAGE_1'] = data_['PREVAILING_WAGE_1'].apply(str2num)\n",
    "    data_['annual_wage'] = data_['WAGE_RATE_1'] * \\\n",
    "        data_['RATE_PER_1'].apply(rp2num)\n",
    "    data_['annual_prevailing_wage'] = data_[\n",
    "        'PREVAILING_WAGE_1']*data_['RATE_PER_1'].apply(rp2num)\n",
    "    # change the columns' name as required and retain necessary cols\n",
    "    col_trans_dict = {'SUBMITTED_DATE': 'date', 'CASE_NO': 'case_number', 'NAME': 'employer', 'JOB_TITLE': 'job_title',\n",
    "                      'JOB_CODE': 'job_code', 'APPROVAL_STATUS': 'approval_status',\n",
    "                      'CITY_1': 'city', 'STATE_1': 'state'}\n",
    "    data_ = data_.rename(columns=col_trans_dict)\n",
    "    # fax data don't contain some certain fields, set them to nan\n",
    "    missing_cols = ['tot_foreign_positions', 'naic_code', 'soc_name', 'county']\n",
    "    data_ = pd.concat([data_, pd.DataFrame(columns=missing_cols)], axis=1)\n",
    "    return data_[retain_fields]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we apply the function `process_efile_data` to the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T23:21:16.464070Z",
     "start_time": "2019-09-17T23:20:51.305589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac506c22ace4faaa921df72e3bbb1df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for year in tqdm_notebook(range(2002,2008)):\n",
    "    year_str = str(year)[-2:]\n",
    "    globals()['efile_'+year_str] = process_efile_data(globals()['efile_'+year_str],year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H1B data 08-18 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For data between 08 and 18, there's only one source of data for each year (except 2009, in which we also also have a efile-source of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T23:22:23.972409Z",
     "start_time": "2019-09-17T23:21:16.464070Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92bf3ee5b1544ef0b2af30c2dfea83ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (22,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (14,15,16,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for year in tqdm_notebook(range(2008, 2019)):\n",
    "    year_str = str(year)[-2:]\n",
    "    globals()['h1b_'+year_str] = pd.read_csv('dataset/H-1B_FY'+year_str+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## efile 09 h1b 08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For H1B data in 2008 and efile data in 2009, their formats are very similar to those of efile data 02-07, so we only need to do some simple parsing and apply the function `process_efile_data` to them："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T23:22:28.776989Z",
     "start_time": "2019-09-17T23:22:23.972409Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "efile_09 = pd.read_csv('dataset/H-1B_FY09_efile.csv')\n",
    "\n",
    "\n",
    "def rp2num(x):\n",
    "    '''\n",
    "    change RatePer to frequency number\n",
    "    '''\n",
    "    trans_dict = {'YR': 1, 'MTH': 12, 'BI': 26, 'WK': 52, 'HR': 2080}\n",
    "    try:\n",
    "        return trans_dict[x]\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "efile_09 = efile_09[efile_09['PROGRAM_DESIGNATION'] == 'R']\n",
    "efile_09.drop(['PROGRAM_DESIGNATION', 'WITHDRAWN'], axis=1, inplace=True)\n",
    "efile_09 = efile_09.rename(\n",
    "    columns={'OCCUPATIONAL_CODE': 'JOB_CODE', 'EMPLOYER_NAME': 'NAME'})\n",
    "# efile_09.columns = efile_cols\n",
    "efile_09 = process_efile_data(efile_09, 2009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T23:22:32.541349Z",
     "start_time": "2019-09-17T23:22:28.776989Z"
    }
   },
   "outputs": [],
   "source": [
    "def rp2num(x):\n",
    "    '''\n",
    "    change RatePer to frequency number\n",
    "    '''\n",
    "    trans_dict = {'yr':1, 'mth':12, 'bi':26, 'wk':52, 'hr':2080}\n",
    "    try:\n",
    "        return trans_dict[x]\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "h1b_08 = h1b_08[h1b_08['PROGRAM']=='R']\n",
    "h1b_08 = h1b_08.drop(['PROGRAM','WITHDRAWN','OCCUPATIONAL_TITLE'],axis=1)\n",
    "h1b_08 = process_efile_data(h1b_08, 2008)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h1b 09-18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For H1B data in the periods of 2009-2018:\n",
    "- we extract H1B data by specifying the column `VISA_CLASS` to be **H-1B**\n",
    "- For year 2009-2014, the columns' names have significant differences from those of year 2015-2018, so we need to rename them. Also, the field `county` is missing, set it to `np.nan`\n",
    "- For year 2015, the `wage` field is in the format of `\"a number-a number\"`. we need to deal with it using the function `range2num`\n",
    "- The fields `annual_wage`, `annual_prevailing_wage` need to be calculated using wages and units. So, we need to convert wages and units from string-type to numerical-type using function `str2num` and `rp2num`\n",
    "- We convert the type of `date` from string to datetime using the function `str2time`\n",
    "- We add a column `year` to represent the year of data source\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T23:22:32.572276Z",
     "start_time": "2019-09-17T23:22:32.541349Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def str2num(x):\n",
    "    '''\n",
    "    change string-type number to float\n",
    "    '''    \n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        x = x.replace(',','')\n",
    "        if x[0] == '$':\n",
    "            x = x[1:]\n",
    "        try:\n",
    "            return float(x)\n",
    "        except:\n",
    "            return np.nan\n",
    "    \n",
    "def rp2num(x):\n",
    "    '''\n",
    "    change RatePer to frequency number\n",
    "    '''\n",
    "    trans_dict = {'Year':1, 'Month':12, 'Bi-Weekly':26, 'Week':52,'Hour':2080}\n",
    "    try:\n",
    "        return trans_dict[x]\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "def str2time(x):\n",
    "    '''\n",
    "    change string-type time to datetime\n",
    "    '''\n",
    "    try:\n",
    "        return datetime.strptime(x,'%Y/%m/%d')\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "def range2num(x):\n",
    "    '''\n",
    "    change wage range to number\n",
    "    '''\n",
    "    try:\n",
    "        return float(x.split('-')[0].strip())\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "cols_mod_dict = {\n",
    "    'LCA_CASE_SUBMIT': 'CASE_SUBMITTED',\n",
    "    'LCA_CASE_NUMBER': 'CASE_NUMBER',\n",
    "    'LCA_CASE_EMPLOYER_NAME': 'EMPLOYER_NAME',\n",
    "    'LCA_CASE_NAICS_CODE': 'NAICS_CODE',\n",
    "    'LCA_CASE_JOB_TITLE': 'JOB_TITLE',\n",
    "    'LCA_CASE_SOC_CODE': 'SOC_CODE',\n",
    "    'LCA_CASE_SOC_NAME': 'SOC_NAME',\n",
    "    'STATUS': 'CASE_STATUS',\n",
    "    'LCA_CASE_WAGE_RATE_FROM': 'WAGE_RATE_OF_PAY_FROM',\n",
    "    'LCA_CASE_WAGE_RATE_UNIT': 'WAGE_UNIT_OF_PAY',\n",
    "    'PW_1': 'PREVAILING_WAGE',\n",
    "    'PW_UNIT_1': 'PW_UNIT_OF_PAY',\n",
    "    'LCA_CASE_WORKLOC1_CITY': 'WORKSITE_CITY',\n",
    "    'LCA_CASE_WORKLOC1_STATE': 'WORKSITE_STATE'\n",
    "}\n",
    "\n",
    "\n",
    "def process_h1b_data(data, year):\n",
    "    '''\n",
    "    data parsing function for h1b data from 09 to 18\n",
    "    '''\n",
    "    data_ = data.copy()\n",
    "    # extra parsing for 07's data\n",
    "    if year in range(2009,2015):\n",
    "        if year == 2010:\n",
    "            data_['LCA_CASE_WAGE_RATE_UNIT'] = data_['PW_UNIT_1']\n",
    "            data_ = data_.rename(columns={'WORK_LOCATION_CITY1':'WORKSITE_CITY', 'WORK_LOCATION_STATE1':'WORKSITE_STATE'})\n",
    "        data_ = data_.rename(columns=cols_mod_dict)\n",
    "        data_['WORKSITE_COUNTY'] = np.nan\n",
    "    elif year==2015:\n",
    "        data_ = data_.rename(columns={'TOTAL WORKERS':'TOTAL_WORKERS','NAIC_CODE':'NAICS_CODE'})\n",
    "        data_['WAGE_RATE_OF_PAY_FROM'] = data_['WAGE_RATE_OF_PAY'].apply(range2num)\n",
    "    elif year==2016:\n",
    "        data_ = data_.rename(columns={'NAIC_CODE':'NAICS_CODE'})   \n",
    "    # choose the samples of H1B\n",
    "    try:\n",
    "        data_ = data_[data_['VISA_CLASS']=='H-1B']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    used_cols = ['CASE_SUBMITTED', 'CASE_NUMBER', 'EMPLOYER_NAME','TOTAL_WORKERS', 'NAICS_CODE', 'JOB_TITLE',\n",
    "                 'SOC_CODE', 'SOC_NAME', 'CASE_STATUS', 'WAGE_RATE_OF_PAY_FROM', 'WAGE_UNIT_OF_PAY', 'PREVAILING_WAGE',\n",
    "                 'PW_UNIT_OF_PAY', 'WORKSITE_CITY', 'WORKSITE_STATE', 'WORKSITE_COUNTY']\n",
    "    data_ = data_[used_cols]\n",
    "    data_['year'] = year\n",
    "    data_['CASE_SUBMITTED'] = data_['CASE_SUBMITTED'].apply(str2time)\n",
    "    data_['WAGE_RATE_OF_PAY_FROM'] = data_['WAGE_RATE_OF_PAY_FROM'].apply(str2num)\n",
    "    data_['PREVAILING_WAGE'] = data_['PREVAILING_WAGE'].apply(str2num)\n",
    "    data_['annual_wage'] = data_['WAGE_RATE_OF_PAY_FROM'] * data_['WAGE_UNIT_OF_PAY'].apply(rp2num)\n",
    "    data_['annual_prevailing_wage'] = data_['PREVAILING_WAGE']*data_['PW_UNIT_OF_PAY'].apply(rp2num)\n",
    "    # change the columns' name as required and retain necessary cols\n",
    "    col_trans_dict = {'CASE_SUBMITTED': 'date', 'CASE_NUMBER': 'case_number', 'EMPLOYER_NAME': 'employer',\n",
    "                      'TOTAL_WORKERS':'tot_foreign_positions', 'NAICS_CODE':'naic_code', 'JOB_TITLE': 'job_title',\n",
    "                      'SOC_CODE': 'job_code', 'SOC_NAME': 'soc_name', 'CASE_STATUS': 'approval_status',\n",
    "                      'WORKSITE_CITY': 'city', 'WORKSITE_STATE': 'state','WORKSITE_COUNTY':'county'}\n",
    "    data_ = data_.rename(columns=col_trans_dict)\n",
    "    return data_[retain_fields]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the function `process_h1b_data` to data in the periods of 2009-2018:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T23:23:37.612618Z",
     "start_time": "2019-09-17T23:22:32.577854Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a979f11840d4f3d83e8777d94f171ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for year in tqdm_notebook(range(2009,2019)):\n",
    "    globals()['h1b_'+str(year)[-2:]] = process_h1b_data(globals()['h1b_'+str(year)[-2:]],year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we concatenate the dataframes for years from 2008 to 2018 and obtain the dataframe `h1b_0818`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T23:23:44.180811Z",
     "start_time": "2019-09-17T23:23:37.612618Z"
    }
   },
   "outputs": [],
   "source": [
    "h1b_0818 = pd.concat([h1b_08,efile_09]+[globals()['h1b_'+str(x)[-2:]] for x in range(2009,2019)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataframe to `h1b_0818.pkl`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T23:24:12.800931Z",
     "start_time": "2019-09-17T23:23:44.180811Z"
    }
   },
   "outputs": [],
   "source": [
    "h1b_0818.to_pickle('dataset/h1b_0818.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we concatenate all the dataframes for years in all periods and obtain the dataframe `h1b_all`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T23:24:20.717356Z",
     "start_time": "2019-09-17T23:24:12.887503Z"
    }
   },
   "outputs": [],
   "source": [
    "fax_list = [globals()['fax_'+str(x)[-2:]] for x in range(2002,2007)]\n",
    "efile_list = [globals()['efile_'+str(x)[-2:]] for x in range(2002,2008)]\n",
    "h1b_all = pd.concat(fax_list+efile_list+[h1b_0818], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataframe to `h1b_all.pkl`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T23:25:23.958966Z",
     "start_time": "2019-09-17T23:24:20.717356Z"
    }
   },
   "outputs": [],
   "source": [
    "h1b_all.to_pickle('dataset/h1b_all.pkl')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 291.65666600000003,
   "position": {
    "height": "318.656px",
    "left": "762px",
    "right": "20px",
    "top": "86px",
    "width": "441.667px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
